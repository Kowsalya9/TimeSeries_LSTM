**Advanced Time Series Forecasting with Deep Learning and Explainability (LSTM/Transformer)**

The project description outlines several complex technical requirements:
  Model Architectures: Using Long Short-Term Memory (LSTM) or basic Transformer models for multivariate forecasting.
  Data Handling: Working with non-stationary data, likely from financial or sensor datasets (e.g., Kaggle).
  Preprocessing: Includes feature engineering (lag features, rolling statistics) and data normalization.
  Explainability: A key requirement is model interpretability using SHAP values or Attention Weight visualization to explain why a prediction was made.
